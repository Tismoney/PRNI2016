{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from reskit.norms import binar_norm, wbysqdist\n",
    "from reskit.norms import spectral_norm\n",
    "\n",
    "from reskit.features import degrees,  pagerank\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def orig(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from reskit.core import Transformer, Pipeliner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция считывания данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_autism(path_to_read='Data/dti/', distances=True):\n",
    "    def get_autism_distances(loc_name):\n",
    "        with open(loc_name, 'r') as f:\n",
    "            read_data = f.readlines()\n",
    "\n",
    "        read_data = pd.DataFrame(\n",
    "            np.array([np.array(item[:-1].split()).astype(int) for item in read_data]))\n",
    "\n",
    "        return read_data\n",
    "\n",
    "    def get_distance_matrix(coords):\n",
    "        if type(coords) == pd.core.frame.DataFrame:\n",
    "            coords = coords.values\n",
    "        elif type(coords) != np.ndarray:\n",
    "            print('Provide either pandas df or numpy array!')\n",
    "            return -1\n",
    "\n",
    "        shape = len(coords)\n",
    "        dist_matrix = np.zeros((shape, shape))\n",
    "        del shape\n",
    "        for i in range(len(coords)):\n",
    "            for j in range(i + 1, len(coords)):\n",
    "                dist_matrix[i, j] = np.linalg.norm(coords[i, :] - coords[j, :])\n",
    "                dist_matrix[j, i] = dist_matrix[i, j]\n",
    "        return dist_matrix\n",
    "\n",
    "    target_vector = []  # this will be a target vector (diagnosis)\n",
    "    matrices = []  # this will be a list of connectomes\n",
    "    all_files = sorted(os.listdir(path_to_read))\n",
    "    matrix_files = [\n",
    "        item for item in all_files if 'DTI_connectivity' in item and 'All' not in item]\n",
    "    distance_files = [\n",
    "        item for item in all_files if 'DTI_region_xyz_centers' in item and 'All' not in item]\n",
    "\n",
    "    # for each file in a sorted (!) list of files:\n",
    "    for filename in matrix_files:\n",
    "\n",
    "        A_dataframe = pd.read_csv(\n",
    "            path_to_read + filename, sep='   ', header=None, engine='python')\n",
    "        A = A_dataframe.values  # we will use a list of numpy arrays, NOT pandas dataframes\n",
    "        matrices.append(A)# append a matrix to our list\n",
    "        if \"ASD\" in filename:\n",
    "            target_vector.append(1)\n",
    "        elif \"TD\" in filename:\n",
    "            target_vector.append(0)\n",
    "    asd_dict = {}\n",
    "    asd_dict['X'] = np.array(matrices)\n",
    "    asd_dict['y'] = np.array(target_vector)\n",
    "    if distances:\n",
    "        dist_matrix_list = []\n",
    "        for item in distance_files:\n",
    "            # print(item)\n",
    "            cur_coord = get_autism_distances(path_to_read + item)\n",
    "            cur_dist_mtx = get_distance_matrix(cur_coord)\n",
    "            dist_matrix_list += [cur_dist_mtx]\n",
    "\n",
    "        asd_dict['dist'] = np.array(dist_matrix_list)\n",
    "\n",
    "    return asd_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция понижения ранга матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_eig(data, k = 0):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        indeces_del = range(curs.size)[(curs.size - k):]\n",
    "        new_data['X'][i] = np.delete(vecs*curs, indeces_del, axis=1).astype('float')\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделаем один пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = 'Data/dti/'\n",
    "data = Transformer(get_autism).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Transformer(matrix_eig, {'data': data, 'k': 40}).fit_transform(data)\n",
    "data = Transformer(degrees, collect=['degrees']).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = data \n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('selector', VarianceThreshold()), ('scaler', MinMaxScaler()), ('classifier', LogisticRegression())] \n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = dict(classifier__penalty=['l1', 'l2'])\n",
    "scoring = 'roc_auc'\n",
    "grid_clf = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring=scoring, n_jobs=-1, cv=grid_cv)\n",
    "grid_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps[-1] = steps[-1][0], grid_clf.best_estimator_\n",
    "pipeline = Pipeline(steps)\n",
    "scores = cross_val_score(pipeline, X, y, scoring=scoring, cv=eval_cv, n_jobs=-1)\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Приведу некоторые результаты для различных К\n",
    "\n",
    "|       scores       |         std        |  k |\n",
    "|      :------:      |        :---:       | :-:|\n",
    "| 0.59233333333333338| 0.12568081264324588|  0 |\n",
    "| 0.59233333333333338| 0.12568081264324588|  1 | \n",
    "| 0.59233333333333338| 0.12568081264324588|  2 | \n",
    "| 0.59433333333333338| 0.13016271867679058| 10 |\n",
    "| 0.61133333333333328| 0.16110865898517063| 20 |\n",
    "| 0.63233333333333341| 0.16096272860510288| 30 |\n",
    "| 0.63233333333333341| 0.16096272860510288| 40 |\n",
    "| 0.63233333333333341| 0.16096272860510288| 45 |\n",
    "| 0.54400000000000004| 0.27115309328864384| 50 |\n",
    "| 0.21695468036742913| 0.22945079356294823| 75 |\n",
    "| 0.49466666666666664| 0.21695468036742913| 100|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Попробуем сделать это, используя класс Papiliner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь возникают проблемы, из-за того, что работая с один пайплайном мы явно можем задать парамеры функции. Тут же сделать это сложнее.\n",
    "\n",
    "Есть несколько решений:  \n",
    "1. Задавать k по дефолту в функции  \n",
    "2. Задавать параметр data функции matrix_eig через стороннюю переменную, расчитанную ранее\n",
    "\n",
    "На мой взгляд, лучши решением будет первый вариант. Поэтому на нем я и остановился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orig_vec(data):\n",
    "    matrices = []\n",
    "    for i in  data['X']:\n",
    "        matrices.append(np.hstack(i))\n",
    "    data['X_vec'] = matrices\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_eig_k(data, k = 30):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        indeces_del = range(curs.size)[(curs.size - k):]\n",
    "        new_data['X'][i] = np.delete(vecs, indeces_del, axis=1).astype('float')\n",
    "    return orig_vec(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_matrix_eig(data, k = 30):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        vecs = vecs * curs\n",
    "        indeces_del = range(curs.size)[(curs.size - k):]\n",
    "        new_data['X'][i] = np.delete(vecs, indeces_del, axis=1).astype('float')\n",
    "    return new_data\n",
    "\n",
    "def degrees_eig(data, k = 30):\n",
    "    return degrees(data_matrix_eig(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_svd_50(data, k = 50):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        A, B, C = np.linalg.svd(data['X'][i])\n",
    "        indeces_del = range(B.size)[(B.size - k):]\n",
    "        A_new = np.delete(A, indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=0)\n",
    "        C_new = np.delete(C, indeces_del, axis=1)\n",
    "        new_data['X'][i] = A_new.dot(B_new).dot(C_new).astype('float')\n",
    "    return orig_vec(new_data)\n",
    "\n",
    "def matrix_svd_100(data, k = 100):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        A, B, C = np.linalg.svd(data['X'][i])\n",
    "        indeces_del = range(B.size)[(B.size - k):]\n",
    "        A_new = np.delete(A, indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=0)\n",
    "        C_new = np.delete(C, indeces_del, axis=1)\n",
    "        new_data['X'][i] = A_new.dot(B_new).dot(C_new).astype('float')\n",
    "    return orig_vec(new_data)\n",
    "\n",
    "def matrix_svd_150(data, k = 150):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        A, B, C = np.linalg.svd(data['X'][i])\n",
    "        indeces_del = range(B.size)[(B.size - k):]\n",
    "        A_new = np.delete(A, indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=0)\n",
    "        C_new = np.delete(C, indeces_del, axis=1)\n",
    "        new_data['X'][i] = A_new.dot(B_new).dot(C_new).astype('float')\n",
    "    return orig_vec(new_data)\n",
    "\n",
    "def matrix_svd_200(data, k = 200):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        A, B, C = np.linalg.svd(data['X'][i])\n",
    "        indeces_del = range(B.size)[(B.size - k):]\n",
    "        A_new = np.delete(A, indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=0)\n",
    "        C_new = np.delete(C, indeces_del, axis=1)\n",
    "        new_data['X'][i] = A_new.dot(B_new).dot(C_new).astype('float')\n",
    "    return orig_vec(new_data)\n",
    "\n",
    "def matrix_svd_250(data, k = 250):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        A, B, C = np.linalg.svd(data['X'][i])\n",
    "        indeces_del = range(B.size)[(B.size - k):]\n",
    "        A_new = np.delete(A, indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=1)\n",
    "        B_new = np.delete(np.diag(B), indeces_del, axis=0)\n",
    "        C_new = np.delete(C, indeces_del, axis=1)\n",
    "        new_data['X'][i] = A_new.dot(B_new).dot(C_new).astype('float')\n",
    "    return orig_vec(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_50</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_100</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_150</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_250</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Weighters Normalizers Featurizers      Selectors Scalers  \\\n",
       "0  UCLAsource     origW    spectral       origF  var_threshold  minmax   \n",
       "1  UCLAsource     origW    spectral      svd_50  var_threshold  minmax   \n",
       "2  UCLAsource     origW    spectral     svd_100  var_threshold  minmax   \n",
       "3  UCLAsource     origW    spectral     svd_150  var_threshold  minmax   \n",
       "4  UCLAsource     origW    spectral     svd_200  var_threshold  minmax   \n",
       "5  UCLAsource     origW    spectral     svd_250  var_threshold  minmax   \n",
       "6  UCLAsource     origW    spectral    low_rank  var_threshold  minmax   \n",
       "\n",
       "  Classifiers  \n",
       "0          LR  \n",
       "1          LR  \n",
       "2          LR  \n",
       "3          LR  \n",
       "4          LR  \n",
       "5          LR  \n",
       "6          LR  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1)\n",
    "\n",
    "data = [('UCLAsource', Transformer(get_autism))]\n",
    "\n",
    "#Only low_rank\n",
    "weighters = [('origW', Transformer(orig)),\n",
    "             #('binar', Transformer(binar_norm)),\n",
    "             #('wbysqdist', Transformer(wbysqdist)),\n",
    "            ]\n",
    "\n",
    "\n",
    "normalizers = [#('origN', Transformer(orig)),\n",
    "               ('spectral', Transformer(spectral_norm))\n",
    "              ]\n",
    "\n",
    "featurizers = [('origF', Transformer(orig_vec, collect=['X_vec'])),\n",
    "               ('svd_50', Transformer(matrix_svd_50, collect=['X_vec'])),\n",
    "               ('svd_100', Transformer(matrix_svd_100, collect=['X_vec'])),\n",
    "               ('svd_150', Transformer(matrix_svd_150, collect=['X_vec'])),\n",
    "               ('svd_200', Transformer(matrix_svd_200, collect=['X_vec'])),\n",
    "               ('svd_250', Transformer(matrix_svd_250, collect=['X_vec'])),\n",
    "               #('degrees', Transformer(degrees, collect=['degrees'])),\n",
    "               #('degrees_eig', Transformer(degrees_eig, collect=['degrees'])),\n",
    "               ('low_rank', Transformer(matrix_eig_k, collect=['X_vec']))\n",
    "               ]\n",
    "\n",
    "selectors = [('var_threshold', VarianceThreshold())]\n",
    "\n",
    "scalers = [('minmax', MinMaxScaler()),\n",
    "           ('origS', FunctionTransformer(orig))]\n",
    "\n",
    "#For tests, don`t use XGB, it needs a lot of time\n",
    "classifiers = [('LR', LogisticRegression()),\n",
    "               #('RF', RandomForestClassifier()),\n",
    "               #('SVC', SVC()),\n",
    "               #('XGB', XGBClassifier(nthread=1)),\n",
    "               #('SGD', SGDClassifier())\n",
    "              ]\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "banned_combos = [#('UCLAsource', 'origN'),\n",
    "                 #('UCLAsource', 'origF'),\n",
    "                 ('UCLAbaseline', 'degrees'),\n",
    "                 ('UCLAbaseline', 'binar'),\n",
    "                 ('UCLAbaseline', 'wbysqdist'),\n",
    "                 ('UCLAbaseline', 'spectral'),\n",
    "                 ('UCLAbaseline', 'low_rank'),\n",
    "                 ('LR', 'origS'),\n",
    "                 ('SVC', 'origS'),\n",
    "                 ('SGD', 'origS'),\n",
    "                 ('RF', 'minmax'),\n",
    "                 ('XGB', 'minmax')]\n",
    "\n",
    "param_grid = dict(\n",
    "    LR=dict(\n",
    "        C=[0.01, 0.05, 0.1] + [0.05*i for i in range(3, 21)],\n",
    "        max_iter=[50, 100, 500],\n",
    "        penalty=['l1', 'l2']\n",
    "    ),\n",
    "    SGD=dict(\n",
    "        alpha=[0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "        l1_ratio=[0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        loss=['hinge', 'log', 'modified_huber'],\n",
    "        n_iter=[50, 100, 200],\n",
    "        penalty=['elasticnet']\n",
    "    ),\n",
    "    SVC=dict(\n",
    "        C=[0.0005, 0.001, 0.005, 0.01] + [i*0.05 for i in range(1,11)],\n",
    "        degree=[2, 3, 4],\n",
    "        kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        max_iter=[50, 100, 150],\n",
    "    ),\n",
    "    RF=dict(\n",
    "        criterion=['entropy', 'gini'],\n",
    "        max_depth=[3, 5, 7, 10, 20],\n",
    "        max_features=['log2', 'sqrt'] + [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0],\n",
    "        n_estimators=[10, 50, 100, 200, 500]\n",
    "    ),\n",
    "    XGB=dict(\n",
    "        colsample_bytree=[0.01] + [0.05*i for i in range(1,21)],\n",
    "        learning_rate=[0.01*i for i in range(1,6)] + [0.05*i for i in range(2,11)],\n",
    "        max_depth=[i for i in range(1,12)],\n",
    "        n_estimators=[10, 50, 100, 200, 500],\n",
    "        nthread=[1],\n",
    "        reg_alpha=[0, 1],\n",
    "        reg_lambda=[0, 1],\n",
    "        subsample=[0.5, 0.7, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe = Pipeliner(steps, eval_cv=eval_cv, grid_cv=grid_cv, param_grid=param_grid, banned_combos=banned_combos)\n",
    "pipe.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 1/7\n",
      "Line: 2/7\n",
      "Line: 3/7\n",
      "Line: 4/7\n",
      "Line: 5/7\n",
      "Line: 6/7\n",
      "Line: 7/7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>grid_roc_auc_mean</th>\n",
       "      <th>grid_roc_auc_std</th>\n",
       "      <th>grid_roc_auc_best_params</th>\n",
       "      <th>eval_roc_auc_mean</th>\n",
       "      <th>eval_roc_auc_std</th>\n",
       "      <th>eval_roc_auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.579433</td>\n",
       "      <td>0.187257</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1, 'max_iter': 50}</td>\n",
       "      <td>0.557667</td>\n",
       "      <td>0.175297</td>\n",
       "      <td>[ 0.56666667  0.56        0.6         0.75    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_50</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.173642</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.35000000000000003, 'm...</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.162311</td>\n",
       "      <td>[ 0.6   0.76  0.64  0.85  0.75  0.45  0.35  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_100</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.577128</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.25, 'max_iter': 50}</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.224154</td>\n",
       "      <td>[ 0.76666667  0.76        0.24        0.75    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_150</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.679433</td>\n",
       "      <td>0.168034</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.25, 'max_iter': 50}</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.206184</td>\n",
       "      <td>[ 0.43333333  0.76        0.64        0.75    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.707801</td>\n",
       "      <td>0.142738</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.65, 'max_iter': 50}</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.183793</td>\n",
       "      <td>[ 0.7   0.52  0.28  0.9   0.7   0.65  0.75  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_250</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.562411</td>\n",
       "      <td>0.195565</td>\n",
       "      <td>{'penalty': 'l1', 'C': 1.0, 'max_iter': 500}</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.185755</td>\n",
       "      <td>[ 0.4   0.72  0.48  0.35  0.45  0.95  0.65  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.503369</td>\n",
       "      <td>0.170741</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.01, 'max_iter': 50}</td>\n",
       "      <td>0.525333</td>\n",
       "      <td>0.0929301</td>\n",
       "      <td>[ 0.63333333  0.64        0.48        0.5     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Weighters Normalizers Featurizers      Selectors Scalers  \\\n",
       "0  UCLAsource     origW    spectral       origF  var_threshold  minmax   \n",
       "1  UCLAsource     origW    spectral      svd_50  var_threshold  minmax   \n",
       "2  UCLAsource     origW    spectral     svd_100  var_threshold  minmax   \n",
       "3  UCLAsource     origW    spectral     svd_150  var_threshold  minmax   \n",
       "4  UCLAsource     origW    spectral     svd_200  var_threshold  minmax   \n",
       "5  UCLAsource     origW    spectral     svd_250  var_threshold  minmax   \n",
       "6  UCLAsource     origW    spectral    low_rank  var_threshold  minmax   \n",
       "\n",
       "  Classifiers grid_roc_auc_mean grid_roc_auc_std  \\\n",
       "0          LR          0.579433         0.187257   \n",
       "1          LR          0.531915         0.173642   \n",
       "2          LR          0.577128           0.1531   \n",
       "3          LR          0.679433         0.168034   \n",
       "4          LR          0.707801         0.142738   \n",
       "5          LR          0.562411         0.195565   \n",
       "6          LR          0.503369         0.170741   \n",
       "\n",
       "                            grid_roc_auc_best_params eval_roc_auc_mean  \\\n",
       "0        {'penalty': 'l2', 'C': 0.1, 'max_iter': 50}          0.557667   \n",
       "1  {'penalty': 'l1', 'C': 0.35000000000000003, 'm...             0.575   \n",
       "2       {'penalty': 'l2', 'C': 0.25, 'max_iter': 50}          0.571667   \n",
       "3       {'penalty': 'l1', 'C': 0.25, 'max_iter': 50}          0.558333   \n",
       "4       {'penalty': 'l1', 'C': 0.65, 'max_iter': 50}              0.61   \n",
       "5       {'penalty': 'l1', 'C': 1.0, 'max_iter': 500}             0.525   \n",
       "6       {'penalty': 'l2', 'C': 0.01, 'max_iter': 50}          0.525333   \n",
       "\n",
       "  eval_roc_auc_std                                eval_roc_auc_scores  \n",
       "0         0.175297  [ 0.56666667  0.56        0.6         0.75    ...  \n",
       "1         0.162311  [ 0.6   0.76  0.64  0.85  0.75  0.45  0.35  0....  \n",
       "2         0.224154  [ 0.76666667  0.76        0.24        0.75    ...  \n",
       "3         0.206184  [ 0.43333333  0.76        0.64        0.75    ...  \n",
       "4         0.183793  [ 0.7   0.52  0.28  0.9   0.7   0.65  0.75  0....  \n",
       "5         0.185755  [ 0.4   0.72  0.48  0.35  0.45  0.95  0.65  0....  \n",
       "6        0.0929301  [ 0.63333333  0.64        0.48        0.5     ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_results('Data/dti/', caching_steps=['Data', 'Weighters', 'Normalizers', 'Featurizers'], scoring=['roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим, как влияет разные способы взвешивания и нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>origN</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>origN</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data  Weighters Normalizers Featurizers      Selectors Scalers  \\\n",
       "0   UCLAsource      origW       origN       origF  var_threshold  minmax   \n",
       "1   UCLAsource      origW       origN     svd_200  var_threshold  minmax   \n",
       "2   UCLAsource      origW    spectral       origF  var_threshold  minmax   \n",
       "3   UCLAsource      origW    spectral     svd_200  var_threshold  minmax   \n",
       "4   UCLAsource      binar       origN       origF  var_threshold  minmax   \n",
       "5   UCLAsource      binar       origN     svd_200  var_threshold  minmax   \n",
       "6   UCLAsource      binar    spectral       origF  var_threshold  minmax   \n",
       "7   UCLAsource      binar    spectral     svd_200  var_threshold  minmax   \n",
       "8   UCLAsource  wbysqdist       origN       origF  var_threshold  minmax   \n",
       "9   UCLAsource  wbysqdist       origN     svd_200  var_threshold  minmax   \n",
       "10  UCLAsource  wbysqdist    spectral       origF  var_threshold  minmax   \n",
       "11  UCLAsource  wbysqdist    spectral     svd_200  var_threshold  minmax   \n",
       "\n",
       "   Classifiers  \n",
       "0           LR  \n",
       "1           LR  \n",
       "2           LR  \n",
       "3           LR  \n",
       "4           LR  \n",
       "5           LR  \n",
       "6           LR  \n",
       "7           LR  \n",
       "8           LR  \n",
       "9           LR  \n",
       "10          LR  \n",
       "11          LR  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1)\n",
    "\n",
    "data = [('UCLAsource', Transformer(get_autism))]\n",
    "\n",
    "#Only low_rank\n",
    "weighters = [('origW', Transformer(orig)),\n",
    "             ('binar', Transformer(binar_norm)),\n",
    "             ('wbysqdist', Transformer(wbysqdist)),\n",
    "            ]\n",
    "\n",
    "\n",
    "normalizers = [('origN', Transformer(orig)),\n",
    "               ('spectral', Transformer(spectral_norm))\n",
    "              ]\n",
    "\n",
    "featurizers = [('origF', Transformer(orig_vec, collect=['X_vec'])),\n",
    "               #('svd_150', Transformer(matrix_svd_150, collect=['X_vec'])),\n",
    "               ('svd_200', Transformer(matrix_svd_200, collect=['X_vec'])),\n",
    "               ]\n",
    "\n",
    "selectors = [('var_threshold', VarianceThreshold())]\n",
    "\n",
    "scalers = [('minmax', MinMaxScaler()),\n",
    "           ('origS', FunctionTransformer(orig))]\n",
    "\n",
    "#For tests, don`t use XGB, it needs a lot of time\n",
    "classifiers = [('LR', LogisticRegression()),\n",
    "               #('RF', RandomForestClassifier()),\n",
    "               #('SVC', SVC()),\n",
    "               #('XGB', XGBClassifier(nthread=1)),\n",
    "               #('SGD', SGDClassifier())\n",
    "              ]\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "banned_combos = [#('UCLAsource', 'origN'),\n",
    "                 #('UCLAsource', 'origF'),\n",
    "                 ('UCLAbaseline', 'degrees'),\n",
    "                 ('UCLAbaseline', 'binar'),\n",
    "                 ('UCLAbaseline', 'wbysqdist'),\n",
    "                 ('UCLAbaseline', 'spectral'),\n",
    "                 ('UCLAbaseline', 'low_rank'),\n",
    "                 ('LR', 'origS'),\n",
    "                 ('SVC', 'origS'),\n",
    "                 ('SGD', 'origS'),\n",
    "                 ('RF', 'minmax'),\n",
    "                 ('XGB', 'minmax')]\n",
    "\n",
    "param_grid = dict(\n",
    "    LR=dict(\n",
    "        C=[0.01, 0.05, 0.1] + [0.05*i for i in range(3, 21)],\n",
    "        max_iter=[50, 100, 500],\n",
    "        penalty=['l1', 'l2']\n",
    "    ),\n",
    "    SGD=dict(\n",
    "        alpha=[0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "        l1_ratio=[0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        loss=['hinge', 'log', 'modified_huber'],\n",
    "        n_iter=[50, 100, 200],\n",
    "        penalty=['elasticnet']\n",
    "    ),\n",
    "    SVC=dict(\n",
    "        C=[0.0005, 0.001, 0.005, 0.01] + [i*0.05 for i in range(1,11)],\n",
    "        degree=[2, 3, 4],\n",
    "        kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        max_iter=[50, 100, 150],\n",
    "    ),\n",
    "    RF=dict(\n",
    "        criterion=['entropy', 'gini'],\n",
    "        max_depth=[3, 5, 7, 10, 20],\n",
    "        max_features=['log2', 'sqrt'] + [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0],\n",
    "        n_estimators=[10, 50, 100, 200, 500]\n",
    "    ),\n",
    "    XGB=dict(\n",
    "        colsample_bytree=[0.01] + [0.05*i for i in range(1,21)],\n",
    "        learning_rate=[0.01*i for i in range(1,6)] + [0.05*i for i in range(2,11)],\n",
    "        max_depth=[i for i in range(1,12)],\n",
    "        n_estimators=[10, 50, 100, 200, 500],\n",
    "        nthread=[1],\n",
    "        reg_alpha=[0, 1],\n",
    "        reg_lambda=[0, 1],\n",
    "        subsample=[0.5, 0.7, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe = Pipeliner(steps, eval_cv=eval_cv, grid_cv=grid_cv, param_grid=param_grid, banned_combos=banned_combos)\n",
    "pipe.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 1/12\n",
      "Line: 2/12\n",
      "Line: 3/12\n",
      "Line: 4/12\n",
      "Line: 5/12\n",
      "Line: 6/12\n",
      "Line: 7/12\n",
      "Line: 8/12\n",
      "Line: 9/12\n",
      "Line: 10/12\n",
      "Line: 11/12\n",
      "Line: 12/12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>grid_roc_auc_mean</th>\n",
       "      <th>grid_roc_auc_std</th>\n",
       "      <th>grid_roc_auc_best_params</th>\n",
       "      <th>eval_roc_auc_mean</th>\n",
       "      <th>eval_roc_auc_std</th>\n",
       "      <th>eval_roc_auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.607801</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1, 'max_iter': 50}</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.159332</td>\n",
       "      <td>[ 0.63333333  0.56        0.64        0.85    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.630142</td>\n",
       "      <td>0.210373</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.05, 'max_iter': 50}</td>\n",
       "      <td>0.628667</td>\n",
       "      <td>0.179005</td>\n",
       "      <td>[ 0.96666667  0.56        0.36        0.8     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.579433</td>\n",
       "      <td>0.187257</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1, 'max_iter': 50}</td>\n",
       "      <td>0.557667</td>\n",
       "      <td>0.175297</td>\n",
       "      <td>[ 0.56666667  0.56        0.6         0.75    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.703901</td>\n",
       "      <td>0.141526</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.65, 'max_iter': 50}</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.206485</td>\n",
       "      <td>[ 0.7   0.52  0.2   0.95  0.7   0.65  0.75  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.557801</td>\n",
       "      <td>0.117517</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.55, 'max_iter': 50}</td>\n",
       "      <td>0.511667</td>\n",
       "      <td>0.126405</td>\n",
       "      <td>[ 0.56666667  0.64        0.36        0.5     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.647872</td>\n",
       "      <td>0.145959</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.01, 'max_iter': 50}</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.143583</td>\n",
       "      <td>[ 0.4   0.84  0.48  0.45  0.4   0.6   0.6   0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.594149</td>\n",
       "      <td>0.174925</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.30000000000000004, 'm...</td>\n",
       "      <td>0.544333</td>\n",
       "      <td>0.127184</td>\n",
       "      <td>[ 0.53333333  0.68        0.48        0.75    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.35000000000000003, 'm...</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.173496</td>\n",
       "      <td>[ 0.7   0.52  0.4   0.6   0.7   0.6   0.65  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>origN</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.607801</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.1, 'max_iter': 50}</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.159332</td>\n",
       "      <td>[ 0.63333333  0.56        0.64        0.85    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>origN</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.601596</td>\n",
       "      <td>0.157347</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.65, 'max_iter': 500}</td>\n",
       "      <td>0.605333</td>\n",
       "      <td>0.148513</td>\n",
       "      <td>[ 0.53333333  0.8         0.52        0.65    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>spectral</td>\n",
       "      <td>origF</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.564539</td>\n",
       "      <td>0.151401</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.05, 'max_iter': 50}</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.182457</td>\n",
       "      <td>[ 0.56666667  0.6         0.56        0.7     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>wbysqdist</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.556915</td>\n",
       "      <td>0.208618</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.01, 'max_iter': 50}</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.110345</td>\n",
       "      <td>[ 0.5   0.68  0.6   0.5   0.55  0.55  0.4   0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data  Weighters Normalizers Featurizers      Selectors Scalers  \\\n",
       "0   UCLAsource      origW       origN       origF  var_threshold  minmax   \n",
       "1   UCLAsource      origW       origN     svd_200  var_threshold  minmax   \n",
       "2   UCLAsource      origW    spectral       origF  var_threshold  minmax   \n",
       "3   UCLAsource      origW    spectral     svd_200  var_threshold  minmax   \n",
       "4   UCLAsource      binar       origN       origF  var_threshold  minmax   \n",
       "5   UCLAsource      binar       origN     svd_200  var_threshold  minmax   \n",
       "6   UCLAsource      binar    spectral       origF  var_threshold  minmax   \n",
       "7   UCLAsource      binar    spectral     svd_200  var_threshold  minmax   \n",
       "8   UCLAsource  wbysqdist       origN       origF  var_threshold  minmax   \n",
       "9   UCLAsource  wbysqdist       origN     svd_200  var_threshold  minmax   \n",
       "10  UCLAsource  wbysqdist    spectral       origF  var_threshold  minmax   \n",
       "11  UCLAsource  wbysqdist    spectral     svd_200  var_threshold  minmax   \n",
       "\n",
       "   Classifiers grid_roc_auc_mean grid_roc_auc_std  \\\n",
       "0           LR          0.607801         0.157715   \n",
       "1           LR          0.630142         0.210373   \n",
       "2           LR          0.579433         0.187257   \n",
       "3           LR          0.703901         0.141526   \n",
       "4           LR          0.557801         0.117517   \n",
       "5           LR          0.647872         0.145959   \n",
       "6           LR          0.594149         0.174925   \n",
       "7           LR          0.716667         0.100271   \n",
       "8           LR          0.607801         0.157715   \n",
       "9           LR          0.601596         0.157347   \n",
       "10          LR          0.564539         0.151401   \n",
       "11          LR          0.556915         0.208618   \n",
       "\n",
       "                             grid_roc_auc_best_params eval_roc_auc_mean  \\\n",
       "0         {'penalty': 'l2', 'C': 0.1, 'max_iter': 50}          0.593333   \n",
       "1        {'penalty': 'l2', 'C': 0.05, 'max_iter': 50}          0.628667   \n",
       "2         {'penalty': 'l2', 'C': 0.1, 'max_iter': 50}          0.557667   \n",
       "3        {'penalty': 'l1', 'C': 0.65, 'max_iter': 50}             0.602   \n",
       "4        {'penalty': 'l1', 'C': 0.55, 'max_iter': 50}          0.511667   \n",
       "5        {'penalty': 'l2', 'C': 0.01, 'max_iter': 50}             0.522   \n",
       "6   {'penalty': 'l2', 'C': 0.30000000000000004, 'm...          0.544333   \n",
       "7   {'penalty': 'l1', 'C': 0.35000000000000003, 'm...             0.617   \n",
       "8         {'penalty': 'l2', 'C': 0.1, 'max_iter': 50}          0.593333   \n",
       "9       {'penalty': 'l1', 'C': 0.65, 'max_iter': 500}          0.605333   \n",
       "10       {'penalty': 'l2', 'C': 0.05, 'max_iter': 50}          0.522667   \n",
       "11       {'penalty': 'l2', 'C': 0.01, 'max_iter': 50}             0.508   \n",
       "\n",
       "   eval_roc_auc_std                                eval_roc_auc_scores  \n",
       "0          0.159332  [ 0.63333333  0.56        0.64        0.85    ...  \n",
       "1          0.179005  [ 0.96666667  0.56        0.36        0.8     ...  \n",
       "2          0.175297  [ 0.56666667  0.56        0.6         0.75    ...  \n",
       "3          0.206485  [ 0.7   0.52  0.2   0.95  0.7   0.65  0.75  0....  \n",
       "4          0.126405  [ 0.56666667  0.64        0.36        0.5     ...  \n",
       "5          0.143583  [ 0.4   0.84  0.48  0.45  0.4   0.6   0.6   0....  \n",
       "6          0.127184  [ 0.53333333  0.68        0.48        0.75    ...  \n",
       "7          0.173496  [ 0.7   0.52  0.4   0.6   0.7   0.6   0.65  0....  \n",
       "8          0.159332  [ 0.63333333  0.56        0.64        0.85    ...  \n",
       "9          0.148513  [ 0.53333333  0.8         0.52        0.65    ...  \n",
       "10         0.182457  [ 0.56666667  0.6         0.56        0.7     ...  \n",
       "11         0.110345  [ 0.5   0.68  0.6   0.5   0.55  0.55  0.4   0....  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_results('Data/dti/', caching_steps=['Data', 'Weighters', 'Normalizers', 'Featurizers'], scoring=['roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем более мощные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_eig_40(data, k = 40):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        indeces_del = range(curs.size)[(curs.size - k):]\n",
    "        new_data['X'][i] = np.delete(vecs, indeces_del, axis=1).astype('float')\n",
    "    return orig_vec(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank_40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank_40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank_40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Weighters Normalizers  Featurizers      Selectors Scalers  \\\n",
       "0  UCLAsource     origW    spectral      svd_200  var_threshold  minmax   \n",
       "1  UCLAsource     origW    spectral      svd_200  var_threshold  minmax   \n",
       "2  UCLAsource     origW    spectral      svd_200  var_threshold  minmax   \n",
       "3  UCLAsource     origW    spectral  low_rank_40  var_threshold  minmax   \n",
       "4  UCLAsource     origW    spectral  low_rank_40  var_threshold  minmax   \n",
       "5  UCLAsource     origW    spectral  low_rank_40  var_threshold  minmax   \n",
       "\n",
       "  Classifiers  \n",
       "0          LR  \n",
       "1         SVC  \n",
       "2         SGD  \n",
       "3          LR  \n",
       "4         SVC  \n",
       "5         SGD  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1)\n",
    "\n",
    "data = [('UCLAsource', Transformer(get_autism))]\n",
    "\n",
    "#Only low_rank\n",
    "weighters = [('origW', Transformer(orig)),\n",
    "             #('binar', Transformer(binar_norm)),\n",
    "             #('wbysqdist', Transformer(wbysqdist)),\n",
    "            ]\n",
    "\n",
    "\n",
    "normalizers = [#('origN', Transformer(orig)),\n",
    "               ('spectral', Transformer(spectral_norm))\n",
    "              ]\n",
    "\n",
    "featurizers = [#('origF', Transformer(orig_vec, collect=['X_vec'])),\n",
    "               #('svd_150', Transformer(matrix_svd_150, collect=['X_vec'])),\n",
    "               ('svd_200', Transformer(matrix_svd_200, collect=['X_vec'])),\n",
    "               ('low_rank_40', Transformer(matrix_eig_40, collect=['X_vec'])),\n",
    "               ]\n",
    "\n",
    "selectors = [('var_threshold', VarianceThreshold())]\n",
    "\n",
    "scalers = [('minmax', MinMaxScaler()),\n",
    "           ('origS', FunctionTransformer(orig))]\n",
    "\n",
    "#For tests, don`t use XGB, it needs a lot of time\n",
    "classifiers = [('LR', LogisticRegression()),\n",
    "               #('RF', RandomForestClassifier()),\n",
    "               ('SVC', SVC()),\n",
    "               #('XGB', XGBClassifier(nthread=1)),\n",
    "               ('SGD', SGDClassifier())\n",
    "              ]\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "banned_combos = [#('UCLAsource', 'origN'),\n",
    "                 #('UCLAsource', 'origF'),\n",
    "                 ('UCLAbaseline', 'degrees'),\n",
    "                 ('UCLAbaseline', 'binar'),\n",
    "                 ('UCLAbaseline', 'wbysqdist'),\n",
    "                 ('UCLAbaseline', 'spectral'),\n",
    "                 ('UCLAbaseline', 'low_rank'),\n",
    "                 ('LR', 'origS'),\n",
    "                 ('SVC', 'origS'),\n",
    "                 ('SGD', 'origS'),\n",
    "                 ('RF', 'minmax'),\n",
    "                 ('XGB', 'minmax')]\n",
    "\n",
    "param_grid = dict(\n",
    "    LR=dict(\n",
    "        C=[0.01, 0.05, 0.1] + [0.05*i for i in range(3, 21)],\n",
    "        max_iter=[50, 100, 500],\n",
    "        penalty=['l1', 'l2']\n",
    "    ),\n",
    "    SGD=dict(\n",
    "        alpha=[0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "        l1_ratio=[0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        loss=['hinge', 'log', 'modified_huber'],\n",
    "        n_iter=[50, 100, 200],\n",
    "        penalty=['elasticnet']\n",
    "    ),\n",
    "    SVC=dict(\n",
    "        C=[0.0005, 0.001, 0.005, 0.01] + [i*0.05 for i in range(1,11)],\n",
    "        degree=[2, 3, 4],\n",
    "        kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        max_iter=[50, 100, 150],\n",
    "    ),\n",
    "    RF=dict(\n",
    "        criterion=['entropy', 'gini'],\n",
    "        max_depth=[3, 5, 7, 10, 20],\n",
    "        max_features=['log2', 'sqrt'] + [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0],\n",
    "        n_estimators=[10, 50, 100, 200, 500]\n",
    "    ),\n",
    "    XGB=dict(\n",
    "        colsample_bytree=[0.01] + [0.05*i for i in range(1,21)],\n",
    "        learning_rate=[0.01*i for i in range(1,6)] + [0.05*i for i in range(2,11)],\n",
    "        max_depth=[i for i in range(1,12)],\n",
    "        n_estimators=[10, 50, 100, 200, 500],\n",
    "        nthread=[1],\n",
    "        reg_alpha=[0, 1],\n",
    "        reg_lambda=[0, 1],\n",
    "        subsample=[0.5, 0.7, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe = Pipeliner(steps, eval_cv=eval_cv, grid_cv=grid_cv, param_grid=param_grid, banned_combos=banned_combos)\n",
    "pipe.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed previous results file -- results.csv.\n",
      "Line: 1/6\n",
      "Line: 2/6\n",
      "Line: 3/6\n",
      "Line: 4/6\n",
      "Line: 5/6\n",
      "Line: 6/6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>grid_roc_auc_mean</th>\n",
       "      <th>grid_roc_auc_std</th>\n",
       "      <th>grid_roc_auc_best_params</th>\n",
       "      <th>eval_roc_auc_mean</th>\n",
       "      <th>eval_roc_auc_std</th>\n",
       "      <th>eval_roc_auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.703369</td>\n",
       "      <td>0.154357</td>\n",
       "      <td>{'penalty': 'l1', 'C': 0.6000000000000001, 'ma...</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.210371</td>\n",
       "      <td>[ 0.8   0.48  0.24  0.9   0.7   0.7   0.65  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.562766</td>\n",
       "      <td>0.208227</td>\n",
       "      <td>{'kernel': 'poly', 'C': 0.4, 'max_iter': 50, '...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.120416</td>\n",
       "      <td>[ 0.73333333  0.8         0.4         0.55    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>svd_200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.696277</td>\n",
       "      <td>0.125825</td>\n",
       "      <td>{'penalty': 'elasticnet', 'loss': 'modified_hu...</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.17408</td>\n",
       "      <td>[ 0.7   0.6   0.24  0.95  0.6   0.7   0.75  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank_40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.49539</td>\n",
       "      <td>0.162425</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.30000000000000004, 'm...</td>\n",
       "      <td>0.543667</td>\n",
       "      <td>0.0928493</td>\n",
       "      <td>[ 0.66666667  0.64        0.48        0.5     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank_40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.530674</td>\n",
       "      <td>0.172475</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 0.001, 'max_iter': 50, ...</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.107559</td>\n",
       "      <td>[ 0.7   0.64  0.52  0.6   0.4   0.4   0.5   0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>spectral</td>\n",
       "      <td>low_rank_40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.564184</td>\n",
       "      <td>0.199671</td>\n",
       "      <td>{'penalty': 'elasticnet', 'loss': 'hinge', 'al...</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>0.116068</td>\n",
       "      <td>[ 0.76666667  0.68        0.52        0.35    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Weighters Normalizers  Featurizers      Selectors Scalers  \\\n",
       "0  UCLAsource     origW    spectral      svd_200  var_threshold  minmax   \n",
       "1  UCLAsource     origW    spectral      svd_200  var_threshold  minmax   \n",
       "2  UCLAsource     origW    spectral      svd_200  var_threshold  minmax   \n",
       "3  UCLAsource     origW    spectral  low_rank_40  var_threshold  minmax   \n",
       "4  UCLAsource     origW    spectral  low_rank_40  var_threshold  minmax   \n",
       "5  UCLAsource     origW    spectral  low_rank_40  var_threshold  minmax   \n",
       "\n",
       "  Classifiers grid_roc_auc_mean grid_roc_auc_std  \\\n",
       "0          LR          0.703369         0.154357   \n",
       "1         SVC          0.562766         0.208227   \n",
       "2         SGD          0.696277         0.125825   \n",
       "3          LR           0.49539         0.162425   \n",
       "4         SVC          0.530674         0.172475   \n",
       "5         SGD          0.564184         0.199671   \n",
       "\n",
       "                            grid_roc_auc_best_params eval_roc_auc_mean  \\\n",
       "0  {'penalty': 'l1', 'C': 0.6000000000000001, 'ma...             0.612   \n",
       "1  {'kernel': 'poly', 'C': 0.4, 'max_iter': 50, '...          0.583333   \n",
       "2  {'penalty': 'elasticnet', 'loss': 'modified_hu...             0.634   \n",
       "3  {'penalty': 'l2', 'C': 0.30000000000000004, 'm...          0.543667   \n",
       "4  {'kernel': 'rbf', 'C': 0.001, 'max_iter': 50, ...             0.541   \n",
       "5  {'penalty': 'elasticnet', 'loss': 'hinge', 'al...          0.551667   \n",
       "\n",
       "  eval_roc_auc_std                                eval_roc_auc_scores  \n",
       "0         0.210371  [ 0.8   0.48  0.24  0.9   0.7   0.7   0.65  0....  \n",
       "1         0.120416  [ 0.73333333  0.8         0.4         0.55    ...  \n",
       "2          0.17408  [ 0.7   0.6   0.24  0.95  0.6   0.7   0.75  0....  \n",
       "3        0.0928493  [ 0.66666667  0.64        0.48        0.5     ...  \n",
       "4         0.107559  [ 0.7   0.64  0.52  0.6   0.4   0.4   0.5   0....  \n",
       "5         0.116068  [ 0.76666667  0.68        0.52        0.35    ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_results('Data/dti/', caching_steps=['Data', 'Weighters', 'Normalizers', 'Featurizers'], scoring=['roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_eig_30(data, k = 30):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        indeces_del = range(curs.size)[(curs.size - k):]\n",
    "        new_data['X'][i] = np.delete(vecs, indeces_del, axis=1).astype('float')\n",
    "    return orig_vec(new_data)\n",
    "\n",
    "def matrix_eig_curs_30(data, k = 30):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['dist'] = data['dist']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        indeces_del = range(curs.size)[(curs.size - k):]\n",
    "        vecs = np.delete(vecs, indeces_del, axis=1)\n",
    "        curs = np.delete(np.diag(curs), indeces_del, axis=1)\n",
    "        new_data['X'][i] = vecs.dot(np.diag(curs)).astype('float')\n",
    "    return orig_vec(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1)\n",
    "\n",
    "data = [('UCLAsource', Transformer(get_autism))]\n",
    "\n",
    "#Only low_rank\n",
    "weighters = [('origW', Transformer(orig)),\n",
    "             ('binar', Transformer(binar_norm))\n",
    "            ]\n",
    "\n",
    "\n",
    "normalizers = [('origN', Transformer(orig)),\n",
    "               ('spectral', Transformer(spectral_norm))\n",
    "              ]\n",
    "\n",
    "featurizers = [('origF', Transformer(orig_vec, collect=['X_vec'])),\n",
    "               ('low_rank_30', Transformer(matrix_eig_30, collect=['X_vec'])),\n",
    "               ('low_rank_30_curs', Transformer(matrix_eig_curs_30, collect=['X_vec']))]\n",
    "\n",
    "selectors = [('var_threshold', VarianceThreshold())]\n",
    "\n",
    "scalers = [('minmax', MinMaxScaler()),\n",
    "           ('origS', FunctionTransformer(orig))]\n",
    "\n",
    "#For tests, don`t use XGB, it needs a lot of time\n",
    "classifiers = [('LR', LogisticRegression()),\n",
    "               #('RF', RandomForestClassifier()),\n",
    "               ('SVC', SVC()),\n",
    "               #('XGB', XGBClassifier(nthread=1)),\n",
    "               ('SGD', SGDClassifier())\n",
    "              ]\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "banned_combos = [\n",
    "                 ('LR', 'origS'),\n",
    "                 ('SVC', 'origS'),\n",
    "                 ('SGD', 'origS'),\n",
    "                 ('RF', 'minmax'),\n",
    "                 ('XGB', 'minmax'),\n",
    "                 ('origW','origN')\n",
    "                 ('binar','spectral')\n",
    "                 ]\n",
    "\n",
    "param_grid = dict(\n",
    "    LR=dict(\n",
    "        C=[0.01, 0.05, 0.1] + [0.05*i for i in range(3, 21)],\n",
    "        max_iter=[50, 100, 500],\n",
    "        penalty=['l1', 'l2']\n",
    "    ),\n",
    "    SGD=dict(\n",
    "        alpha=[0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "        l1_ratio=[0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "        loss=['hinge', 'log', 'modified_huber'],\n",
    "        n_iter=[50, 100, 200],\n",
    "        penalty=['elasticnet']\n",
    "    ),\n",
    "    SVC=dict(\n",
    "        C=[0.0005, 0.001, 0.005, 0.01] + [i*0.05 for i in range(1,11)],\n",
    "        degree=[2, 3, 4],\n",
    "        kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        max_iter=[50, 100, 150],\n",
    "    ),\n",
    "    RF=dict(\n",
    "        criterion=['entropy', 'gini'],\n",
    "        max_depth=[3, 5, 7, 10, 20],\n",
    "        max_features=['log2', 'sqrt'] + [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0],\n",
    "        n_estimators=[10, 50, 100, 200, 500]\n",
    "    ),\n",
    "    XGB=dict(\n",
    "        colsample_bytree=[0.01] + [0.05*i for i in range(1,21)],\n",
    "        learning_rate=[0.01*i for i in range(1,6)] + [0.05*i for i in range(2,11)],\n",
    "        max_depth=[i for i in range(1,12)],\n",
    "        n_estimators=[10, 50, 100, 200, 500],\n",
    "        nthread=[1],\n",
    "        reg_alpha=[0, 1],\n",
    "        reg_lambda=[0, 1],\n",
    "        subsample=[0.5, 0.7, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe = Pipeliner(steps, eval_cv=eval_cv, grid_cv=grid_cv, param_grid=param_grid, banned_combos=banned_combos)\n",
    "pipe.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pipe.get_results('Data/dti/', caching_steps=['Data', 'Weighters', 'Normalizers', 'Featurizers'], scoring=['roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
