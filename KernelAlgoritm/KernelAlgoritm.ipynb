{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from reskit.norms import binar_norm, wbysqdist\n",
    "from reskit.norms import spectral_norm\n",
    "\n",
    "#from reskit.features import degrees,  pagerank\n",
    "\n",
    "from reskit.core import Transformer, Pipeliner\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matrix_eig as me\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def orig(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция считывания данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_autism(path_to_read='../Data/dti/', distances=True):\n",
    "    def get_autism_distances(loc_name):\n",
    "        with open(loc_name, 'r') as f:\n",
    "            read_data = f.readlines()\n",
    "\n",
    "        read_data = pd.DataFrame(\n",
    "            np.array([np.array(item[:-1].split()).astype(int) for item in read_data]))\n",
    "\n",
    "        return read_data\n",
    "\n",
    "    def get_distance_matrix(coords):\n",
    "        if type(coords) == pd.core.frame.DataFrame:\n",
    "            coords = coords.values\n",
    "        elif type(coords) != np.ndarray:\n",
    "            print('Provide either pandas df or numpy array!')\n",
    "            return -1\n",
    "\n",
    "        shape = len(coords)\n",
    "        dist_matrix = np.zeros((shape, shape))\n",
    "        del shape\n",
    "        for i in range(len(coords)):\n",
    "            for j in range(i + 1, len(coords)):\n",
    "                dist_matrix[i, j] = np.linalg.norm(coords[i, :] - coords[j, :])\n",
    "                dist_matrix[j, i] = dist_matrix[i, j]\n",
    "        return dist_matrix\n",
    "\n",
    "    target_vector = []  # this will be a target vector (diagnosis)\n",
    "    matrices = []  # this will be a list of connectomes\n",
    "    all_files = sorted(os.listdir(path_to_read))\n",
    "    matrix_files = [\n",
    "        item for item in all_files if 'DTI_connectivity' in item and 'All' not in item]\n",
    "    distance_files = [\n",
    "        item for item in all_files if 'DTI_region_xyz_centers' in item and 'All' not in item]\n",
    "\n",
    "    # for each file in a sorted (!) list of files:\n",
    "    for filename in matrix_files:\n",
    "\n",
    "        A_dataframe = pd.read_csv(\n",
    "            path_to_read + filename, sep='   ', header=None, engine='python')\n",
    "        A = A_dataframe.values  # we will use a list of numpy arrays, NOT pandas dataframes\n",
    "        matrices.append(A)# append a matrix to our list\n",
    "        if \"ASD\" in filename:\n",
    "            target_vector.append(1)\n",
    "        elif \"TD\" in filename:\n",
    "            target_vector.append(0)\n",
    "    asd_dict = {}\n",
    "    asd_dict['X'] = np.array(matrices)\n",
    "    asd_dict['y'] = np.array(target_vector)\n",
    "    if distances:\n",
    "        dist_matrix_list = []\n",
    "        for item in distance_files:\n",
    "            # print(item)\n",
    "            cur_coord = get_autism_distances(path_to_read + item)\n",
    "            cur_dist_mtx = get_distance_matrix(cur_coord)\n",
    "            dist_matrix_list += [cur_dist_mtx]\n",
    "\n",
    "        asd_dict['dist'] = np.array(dist_matrix_list)\n",
    "\n",
    "    return asd_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Обучим SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Функция понижения размерности \n",
    "def matrix_eig(data, k = 250):\n",
    "    new_data = {}\n",
    "    new_data['y'] = data['y']\n",
    "    new_data['X'] = np.zeros(shape = (data['X'].shape[0], data['X'].shape[1], data['X'].shape[1] - k))\n",
    "    for i in np.arange(data['X'].shape[0]):\n",
    "        curs, vecs = np.linalg.eig(data['X'][i])\n",
    "        indeces_del = curs.argsort()[:k]\n",
    "        vecs_n = np.delete(vecs, indeces_del, axis=1)\n",
    "        curs = np.delete(curs, indeces_del)\n",
    "        new_data['X'][i] = vecs_n.dot(np.diag(curs)).astype('float')\n",
    "    return orig_vec(new_data)\n",
    "\n",
    "#Функция, которая в словаре data из матриц X создает вектора X_vec\n",
    "def orig_vec(data):\n",
    "    matrix = []\n",
    "    for i in  data['X']:\n",
    "        matrix.append(np.hstack(i))\n",
    "    data['X_vec'] = matrix\n",
    "    return data\n",
    "\n",
    "#Функция преобразования матрицы в вектор и наоборот\n",
    "def convert(A, mode, size = 264):\n",
    "    if mode == 'mat2vec':\n",
    "        A_vec = np.hstack(A)\n",
    "        return A_vec\n",
    "        \n",
    "    if mode == 'vec2mat':\n",
    "        A_mat = []\n",
    "        i = 0\n",
    "        while i != A.shape[0]:\n",
    "            A_str = A[0+i:size+i]\n",
    "            A_mat.append(A_str)\n",
    "            i += size\n",
    "        A_mat = np.vstack(A_mat)\n",
    "        return A_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ядро\n",
    "from math import exp\n",
    "\n",
    "def ker(A, B):\n",
    "    #Данные подавются в виде векторов, поэтому преобразуем их в матрицы\n",
    "    A = convert(A, 'vec2mat')\n",
    "    B = convert(B, 'vec2mat')\n",
    "    #Посчитаем расстояние\n",
    "    d = np.linalg.norm(A.dot(A.T) - B.dot(B.T), 'fro')\n",
    "    return exp(-d * 10**-6*par)\n",
    "\n",
    "def my_kernel(X, Xfit):\n",
    "    size1 = np.shape(X)[0]\n",
    "    size2 = np.shape(Xfit)[0]\n",
    "    dist = np.zeros([size1, size2])\n",
    "    for i in range(size1):\n",
    "        for j in range(size2):\n",
    "            dist[i][j] = ker(X[i], Xfit[j])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обычным способом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = matrix_eig(get_autism(\"../Data/dti/\"), k=250)\n",
    "X = data['X_vec']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto',\n",
       "  kernel=<function my_kernel at 0x7f826ce5b050>, max_iter=-1,\n",
       "  probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "  verbose=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel=my_kernel, C=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[0 1 0 1 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print clf.predict(X_test)\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "metrics.roc_auc_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Используя класс Papiliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_245</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_250</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_255</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_260</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Weighters Normalizers   Featurizers      Selectors Scalers  \\\n",
       "0  UCLAsource     origW       origN  low_rank_245  var_threshold   origS   \n",
       "1  UCLAsource     origW       origN  low_rank_250  var_threshold   origS   \n",
       "2  UCLAsource     origW       origN  low_rank_255  var_threshold   origS   \n",
       "3  UCLAsource     origW       origN  low_rank_260  var_threshold   origS   \n",
       "\n",
       "  Classifiers  \n",
       "0         SVC  \n",
       "1         SVC  \n",
       "2         SVC  \n",
       "3         SVC  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1)\n",
    "\n",
    "data =          [('UCLAsource', Transformer(get_autism))]\n",
    "\n",
    "weighters =     [('origW', Transformer(orig)),\n",
    "                #('binar', Transformer(binar_norm))\n",
    "                ]\n",
    "\n",
    "\n",
    "normalizers =   [('origN', Transformer(orig)),\n",
    "                #('spectral', Transformer(spectral_norm))\n",
    "                ]\n",
    "\n",
    "featurizers =   [#('origF', Transformer(orig_vec, collect=['X_vec'])),\n",
    "                 ('low_rank_245', Transformer(me.matrix_eig_245, collect=['X_vec'])),\n",
    "                 ('low_rank_250', Transformer(me.matrix_eig_250, collect=['X_vec'])),\n",
    "                 ('low_rank_255', Transformer(me.matrix_eig_255, collect=['X_vec'])),\n",
    "                 ('low_rank_260', Transformer(me.matrix_eig_260, collect=['X_vec']))\n",
    "                ]\n",
    "\n",
    "selectors =     [('var_threshold', VarianceThreshold())]\n",
    "\n",
    "scalers =       [('minmax', MinMaxScaler()),\n",
    "                  ('origS', FunctionTransformer(orig))\n",
    "                ]\n",
    "\n",
    "\n",
    "classifiers =   [('SVC', SVC())]\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "banned_combos = [\n",
    "                 #('SVC', 'origS'),\n",
    "                 ('SVC', 'minmax'),\n",
    "                 ]\n",
    "\n",
    "param_grid = dict(\n",
    "    SVC=dict(\n",
    "        C=[1.0],\n",
    "        kernel=[my_kernel]\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe = Pipeliner(steps, eval_cv=eval_cv, grid_cv=grid_cv, param_grid=param_grid, banned_combos=banned_combos)\n",
    "pipe.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed previous results file -- results.csv.\n",
      "Line: 1/4\n",
      "Line: 2/4\n",
      "Line: 3/4\n",
      "Line: 4/4\n"
     ]
    }
   ],
   "source": [
    "result = pipe.get_results('../Data/dti/', caching_steps=['Data', 'Weighters', 'Normalizers', 'Featurizers'], scoring=['roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>grid_roc_auc_mean</th>\n",
       "      <th>grid_roc_auc_std</th>\n",
       "      <th>grid_roc_auc_best_params</th>\n",
       "      <th>eval_roc_auc_mean</th>\n",
       "      <th>eval_roc_auc_std</th>\n",
       "      <th>eval_roc_auc_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_245</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.38883</td>\n",
       "      <td>0.195855</td>\n",
       "      <td>{'kernel': &lt;function my_kernel at 0x7f826f8904...</td>\n",
       "      <td>0.382667</td>\n",
       "      <td>0.169344</td>\n",
       "      <td>[ 0.26666667  0.24        0.32        0.45    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_250</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.278723</td>\n",
       "      <td>0.162737</td>\n",
       "      <td>{'kernel': &lt;function my_kernel at 0x7f826f8904...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.131909</td>\n",
       "      <td>[ 0.4   0.2   0.2   0.25  0.3   0.1   0.55  0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_255</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.476064</td>\n",
       "      <td>0.227466</td>\n",
       "      <td>{'kernel': &lt;function my_kernel at 0x7f826f8904...</td>\n",
       "      <td>0.450333</td>\n",
       "      <td>0.191262</td>\n",
       "      <td>[ 0.33333333  0.16        0.36        0.55    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>origW</td>\n",
       "      <td>origN</td>\n",
       "      <td>low_rank_260</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>origS</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.432624</td>\n",
       "      <td>0.192837</td>\n",
       "      <td>{'kernel': &lt;function my_kernel at 0x7f826f8904...</td>\n",
       "      <td>0.507667</td>\n",
       "      <td>0.231291</td>\n",
       "      <td>[ 0.56666667  0.56        0.2         0.75    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Weighters Normalizers   Featurizers      Selectors Scalers  \\\n",
       "0  UCLAsource     origW       origN  low_rank_245  var_threshold   origS   \n",
       "1  UCLAsource     origW       origN  low_rank_250  var_threshold   origS   \n",
       "2  UCLAsource     origW       origN  low_rank_255  var_threshold   origS   \n",
       "3  UCLAsource     origW       origN  low_rank_260  var_threshold   origS   \n",
       "\n",
       "  Classifiers grid_roc_auc_mean grid_roc_auc_std  \\\n",
       "0         SVC           0.38883         0.195855   \n",
       "1         SVC          0.278723         0.162737   \n",
       "2         SVC          0.476064         0.227466   \n",
       "3         SVC          0.432624         0.192837   \n",
       "\n",
       "                            grid_roc_auc_best_params eval_roc_auc_mean  \\\n",
       "0  {'kernel': <function my_kernel at 0x7f826f8904...          0.382667   \n",
       "1  {'kernel': <function my_kernel at 0x7f826f8904...              0.31   \n",
       "2  {'kernel': <function my_kernel at 0x7f826f8904...          0.450333   \n",
       "3  {'kernel': <function my_kernel at 0x7f826f8904...          0.507667   \n",
       "\n",
       "  eval_roc_auc_std                                eval_roc_auc_scores  \n",
       "0         0.169344  [ 0.26666667  0.24        0.32        0.45    ...  \n",
       "1         0.131909  [ 0.4   0.2   0.2   0.25  0.3   0.1   0.55  0....  \n",
       "2         0.191262  [ 0.33333333  0.16        0.36        0.55    ...  \n",
       "3         0.231291  [ 0.56666667  0.56        0.2         0.75    ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
