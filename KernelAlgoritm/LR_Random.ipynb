{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from reskit.norms import binar_norm\n",
    "\n",
    "from reskit.core import Transformer, Pipeliner\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def orig(x):\n",
    "    return x\n",
    "\n",
    "import matrix_eig as me\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_autism(path_to_read='../Data/dti/', distances=True):\n",
    "    def get_autism_distances(loc_name):\n",
    "        with open(loc_name, 'r') as f:\n",
    "            read_data = f.readlines()\n",
    "\n",
    "        read_data = pd.DataFrame(\n",
    "            np.array([np.array(item[:-1].split()).astype(int) for item in read_data]))\n",
    "\n",
    "        return read_data\n",
    "\n",
    "    def get_distance_matrix(coords):\n",
    "        if type(coords) == pd.core.frame.DataFrame:\n",
    "            coords = coords.values\n",
    "        elif type(coords) != np.ndarray:\n",
    "            print('Provide either pandas df or numpy array!')\n",
    "            return -1\n",
    "\n",
    "        shape = len(coords)\n",
    "        dist_matrix = np.zeros((shape, shape))\n",
    "        del shape\n",
    "        for i in range(len(coords)):\n",
    "            for j in range(i + 1, len(coords)):\n",
    "                dist_matrix[i, j] = np.linalg.norm(coords[i, :] - coords[j, :])\n",
    "                dist_matrix[j, i] = dist_matrix[i, j]\n",
    "        return dist_matrix\n",
    "\n",
    "    target_vector = []  # this will be a target vector (diagnosis)\n",
    "    matrices = []  # this will be a list of connectomes\n",
    "    all_files = sorted(os.listdir(path_to_read))\n",
    "    matrix_files = [\n",
    "        item for item in all_files if 'DTI_connectivity' in item and 'All' not in item]\n",
    "    distance_files = [\n",
    "        item for item in all_files if 'DTI_region_xyz_centers' in item and 'All' not in item]\n",
    "\n",
    "    # for each file in a sorted (!) list of files:\n",
    "    for filename in matrix_files:\n",
    "\n",
    "        A_dataframe = pd.read_csv(\n",
    "            path_to_read + filename, sep='   ', header=None, engine='python')\n",
    "        A = A_dataframe.values  # we will use a list of numpy arrays, NOT pandas dataframes\n",
    "        matrices.append(A)# append a matrix to our list\n",
    "        if \"ASD\" in filename:\n",
    "            target_vector.append(1)\n",
    "        elif \"TD\" in filename:\n",
    "            target_vector.append(0)\n",
    "    asd_dict = {}\n",
    "    asd_dict['X'] = np.array(matrices)\n",
    "    asd_dict['y'] = np.array(target_vector)\n",
    "    if distances:\n",
    "        dist_matrix_list = []\n",
    "        for item in distance_files:\n",
    "            # print(item)\n",
    "            cur_coord = get_autism_distances(path_to_read + item)\n",
    "            cur_dist_mtx = get_distance_matrix(cur_coord)\n",
    "            dist_matrix_list += [cur_dist_mtx]\n",
    "\n",
    "        asd_dict['dist'] = np.array(dist_matrix_list)\n",
    "\n",
    "    return asd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'text.usetex'         : True,\n",
    "    'text.latex.unicode'  : True,\n",
    "    'text.latex.preamble' : r\"\\usepackage[T2A]{fontenc}\",\n",
    "    'font.size'           : 15,\n",
    "    'font.family'         : 'lmodern'\n",
    "    }\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "\n",
    "def print_boxplot(file_name, mod, figsize = (10.5,6.5)):\n",
    "    ##################################################################\n",
    "    # Paramatrs:                                                     #\n",
    "    #----------------------------------------------------------------#\n",
    "    # file_name: string, name of file witch has a table with columns:# \n",
    "    #           'eval_roc_auc_scores' and 'Featurizers'              #\n",
    "    #                                                                #\n",
    "    # mod: string, additional information for boxplot                #\n",
    "    #                                                                #\n",
    "    # figsize: w,h tuple in inches                                   #\n",
    "    ##################################################################\n",
    "    data = []\n",
    "    result = pd.read_csv(file_name, index_col=0)\n",
    "    \n",
    "    lables          = result['Featurizers']\n",
    "    array_of_arrays = result['eval_roc_auc_scores']\n",
    "    for tmp in array_of_arrays:\n",
    "        array_str = re.split('[]*[ ,]', tmp)\n",
    "        ##########################################\n",
    "        #Костыль\n",
    "        for i in range(array_str.count('')):\n",
    "            array_str.remove('')\n",
    "        ##########################################\n",
    "        array_fold = []\n",
    "        for i in array_str:\n",
    "            array_fold.append(float(i))\n",
    "        data.append(array_fold)\n",
    "        \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax  = fig.add_subplot(111)\n",
    "    bp  = ax.boxplot(data, 0, '+', labels=lables)\n",
    "    \n",
    "    plt.setp(bp['boxes'],    color='DarkGreen')\n",
    "    plt.setp(bp['whiskers'], color='DarkOrange', linestyle = '-')\n",
    "    plt.setp(bp['medians'],  color='DarkBlue')\n",
    "    plt.setp(bp['caps'],     color='Gray')\n",
    "    \n",
    "    \n",
    "    ax.set_title(r'ROC AUC mean for LogisticRegression (' + mod + ').' )\n",
    "    ax.set_ylabel(r'ROC AUC mean')\n",
    "    ax.set_xlabel(r'k')\n",
    "    ax.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LogRegression and conctrsuct BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ind(ind):\n",
    "    ind_new = []\n",
    "    for i in ind:\n",
    "        for j in range(7):\n",
    "            ind_new.append(i+j)\n",
    "    return ind_new\n",
    "\n",
    "\n",
    "class my_eval:\n",
    "    \n",
    "    def __init__(self, eval_cv):\n",
    "        self.eval = eval_cv\n",
    "        \n",
    "    def split(self, X, y, groups):\n",
    "        ind = np.arange(X.shape[0] / 7) * 7\n",
    "        y_min = y[ind]\n",
    "        \n",
    "        for train_index, test_index in self.eval.split(ind, y_min):\n",
    "            ind_train, ind_test = ind[train_index], ind[test_index]\n",
    "            yield add_ind(ind_train), add_ind(ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_cv = StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=0)\n",
    "\n",
    "eval_cv = my_eval(StratifiedKFold(n_splits=10,\n",
    "                          shuffle=True,\n",
    "                          random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Weighters</th>\n",
       "      <th>Normalizers</th>\n",
       "      <th>Featurizers</th>\n",
       "      <th>Selectors</th>\n",
       "      <th>Scalers</th>\n",
       "      <th>Classifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>Orig</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>0</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>20</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>40</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>60</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>80</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>100</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>120</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>140</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>160</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>180</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>200</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>220</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>240</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UCLAsource</td>\n",
       "      <td>binar</td>\n",
       "      <td>origN</td>\n",
       "      <td>260</td>\n",
       "      <td>var_threshold</td>\n",
       "      <td>minmax</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data Weighters Normalizers Featurizers      Selectors Scalers  \\\n",
       "0   UCLAsource     binar       origN        Orig  var_threshold  minmax   \n",
       "1   UCLAsource     binar       origN           0  var_threshold  minmax   \n",
       "2   UCLAsource     binar       origN          20  var_threshold  minmax   \n",
       "3   UCLAsource     binar       origN          40  var_threshold  minmax   \n",
       "4   UCLAsource     binar       origN          60  var_threshold  minmax   \n",
       "5   UCLAsource     binar       origN          80  var_threshold  minmax   \n",
       "6   UCLAsource     binar       origN         100  var_threshold  minmax   \n",
       "7   UCLAsource     binar       origN         120  var_threshold  minmax   \n",
       "8   UCLAsource     binar       origN         140  var_threshold  minmax   \n",
       "9   UCLAsource     binar       origN         160  var_threshold  minmax   \n",
       "10  UCLAsource     binar       origN         180  var_threshold  minmax   \n",
       "11  UCLAsource     binar       origN         200  var_threshold  minmax   \n",
       "12  UCLAsource     binar       origN         220  var_threshold  minmax   \n",
       "13  UCLAsource     binar       origN         240  var_threshold  minmax   \n",
       "14  UCLAsource     binar       origN         260  var_threshold  minmax   \n",
       "\n",
       "   Classifiers  \n",
       "0           LR  \n",
       "1           LR  \n",
       "2           LR  \n",
       "3           LR  \n",
       "4           LR  \n",
       "5           LR  \n",
       "6           LR  \n",
       "7           LR  \n",
       "8           LR  \n",
       "9           LR  \n",
       "10          LR  \n",
       "11          LR  \n",
       "12          LR  \n",
       "13          LR  \n",
       "14          LR  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('UCLAsource', Transformer(get_autism))]\n",
    "\n",
    "weighters = [('binar', Transformer(binar_norm))]\n",
    "\n",
    "normalizers = [('origN', Transformer(orig))]\n",
    "\n",
    "featurizers = [('Orig',   Transformer(me.orig_vec,       collect=['X_vec'])),\n",
    "               ('0',      Transformer(me.matrix_eig_0,   collect=['X_vec'])),\n",
    "               ('20',     Transformer(me.matrix_eig_20,  collect=['X_vec'])),\n",
    "               ('40',     Transformer(me.matrix_eig_40,  collect=['X_vec'])),\n",
    "               ('60',     Transformer(me.matrix_eig_60,  collect=['X_vec'])),\n",
    "               ('80',     Transformer(me.matrix_eig_80,  collect=['X_vec'])),\n",
    "               ('100',    Transformer(me.matrix_eig_100, collect=['X_vec'])),\n",
    "               ('120',    Transformer(me.matrix_eig_120, collect=['X_vec'])),\n",
    "               ('140',    Transformer(me.matrix_eig_140, collect=['X_vec'])),\n",
    "               ('160',    Transformer(me.matrix_eig_160, collect=['X_vec'])),\n",
    "               ('180',    Transformer(me.matrix_eig_180, collect=['X_vec'])),\n",
    "               ('200',    Transformer(me.matrix_eig_200, collect=['X_vec'])),\n",
    "               ('220',    Transformer(me.matrix_eig_220, collect=['X_vec'])),\n",
    "               ('240',    Transformer(me.matrix_eig_240, collect=['X_vec'])),\n",
    "               ('260',    Transformer(me.matrix_eig_260, collect=['X_vec']))]\n",
    "\n",
    "\n",
    "selectors = [('var_threshold', VarianceThreshold())]\n",
    "\n",
    "scalers = [('minmax', MinMaxScaler())]\n",
    "\n",
    "classifiers = [('LR', LogisticRegression())]\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "param_grid = dict(\n",
    "     LR=dict(\n",
    "        C=[0.01] + [0.1*i for i in range(1, 11)],\n",
    "        max_iter=[50, 100],\n",
    "        penalty=['l1']\n",
    "    )\n",
    "    )\n",
    "\n",
    "banned_combos = []\n",
    "\n",
    "steps = [('Data', data),\n",
    "         ('Weighters', weighters),\n",
    "         ('Normalizers', normalizers),\n",
    "         ('Featurizers', featurizers),\n",
    "         ('Selectors', selectors),\n",
    "         ('Scalers', scalers),\n",
    "         ('Classifiers', classifiers)]\n",
    "\n",
    "pipe = Pipeliner(steps, eval_cv=eval_cv, grid_cv=grid_cv, param_grid=param_grid, banned_combos=banned_combos)\n",
    "pipe.plan_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous results found.\n",
      "Line: 1/15\n"
     ]
    }
   ],
   "source": [
    "pipe.get_results('../Data/dti/', caching_steps=['Data', 'Weighters', 'Normalizers', 'Featurizers'],\n",
    "                 scoring=['roc_auc'], collect_n = 50, results_file = 'LR/binar_eig_rand_m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_boxplot('LR/orig_eig_noabs_m.csv', 'Binar-Orig-MinMax-Rand')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
